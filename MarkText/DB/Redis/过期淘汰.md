# 过期淘汰

## 参考博文

1. [Redis 的数据过期了就会马上删除么？ - 掘金](https://juejin.cn/post/7098256190739578911)

2. [Redis 内存满了怎么办？这样处理才正确 - 掘金](https://juejin.cn/post/7124530633782591496)

3. [Redis 为何使用近似 LRU 算法淘汰数据，而不是真实 LRU？ - 掘金](https://juejin.cn/post/7096052937767518222)

4. [Redis的数据被删除，占用内存咋还那么大？ - 掘金](https://juejin.cn/post/7175041133477625911)

## 过期删除策略

1. 惰性删除
   
   > `key`过期之后不会立马删除，而是等下次访问时再判断是否已过期，若过期则删除

2. 定期删除
   
   > 上面的惰性删除存在一个问题，若过期之后一直没有访问则无法删除，所以`Redis`增加了一个定期删除的策略
   > 
   > 维护一个定时任务，比如每秒执行一次，每次选一定数量的`key`，比如`20`个，然后逐个判断是否过期，若过期则删除，若本次删除的`key`达到样本的`25%`以上则继续，否则跳出

## 淘汰删除策略

> 从上面的过期删除策略来看，存在一定的问题，有些`key`即使过期了也可能一直无法被删除，依然占用空间
> 
> 另外一种情况，若内存空间已满或达到了最大使用限制，如何淘汰掉一些`key`释放出空间给新`key`使用

#### 最大内存限制

1. 运行时设置，需要注意若重启，会失效
   
   ```shell
   # 先进入redis-cli界面
   config set maxmemory 4GB
   ```

2. 配置文件里设置，重启才能生效
   
   ```
   # maxmemory <bytes>
   maxmemory 4294967296
   # 或者
   maxmemory 4GB
   ```

> 需要注意的是，如果 `maxmemory` 为 0 ，在 `64` 位「空间」上则没有限制，而 `32` 位「空间」则有 `3GB` 的隐式限制。

#### 淘汰策略

```
# volatile-lru -> Evict using approximated LRU among the keys with an expire set.
# allkeys-lru -> Evict any key using approximated LRU.
# volatile-lfu -> Evict using approximated LFU among the keys with an expire set.
# allkeys-lfu -> Evict any key using approximated LFU.
# volatile-random -> Remove a random key among the ones with an expire set.
# allkeys-random -> Remove a random key, any key.
# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)
# noeviction -> Don't evict anything, just return an error on write operations.

maxmemory-policy volatile-lru
```

1. `noeviction`，不淘汰，若内存已满，则无法再新增`key`

2. `volatile-`开头的为设置了过期时间的`key`的淘汰策略

3. `allkeys-`开头的为针对所有`key`的淘汰策略

4. `ttl`为最快过期者淘汰

5. `random`为随机淘汰

6. `lru`为`LRU`算法淘汰，也即最近最少访问，以时间来排序

7. `lfu`为`LFU`算法淘汰，也即最近最少访问次数，以访问次数排序

8. 一般我们选择`volatile-lru`，也即设置了过期时间，最近最少访问淘汰

## 内存碎片处理

> 内存实际占用和数据实际大小存在一定的差异，因为数据需要存在内存页里，一般无法完全利用每一块内存页的每一个空间，这就会导致部分内存无法被使用，这个时候就需要我们进行清理了，把数据进行合并，收回不可使用的碎片空间。
> 
> 碎片主要是由于无法提供连续的内存空间，所以我们的`key`不宜过多，容易造成碎片

```shell
# 通过 info memory查看碎片率
# 在1.5以内还算正常，超过了就要考虑清理了
mem_fragmentation_ratio 1.16

# 开启自动清理碎片
CONFIG SET activedefrag yes

# 内存碎片占用的内存达到 200MB，开始清理；
active-defrag-ignore-bytes 200mb
# 内存碎片的空间占系统分配给 Redis 空间的 20% ，开始清理。
active-defrag-threshold-lower 20

# 控制自动清理启动规则，避免占用太多CPU资源导致其他正常命令阻塞
# 自动清理过程中，占用 CPU 时间的比例不低于 20%，从而保证能正常展开清理任务。
active-defrag-cycle-min 20
# 自动清理过程占用的 CPU 时间比例不能高于 50%，超过的话就立刻停止清理，避免对 Redis 的阻塞，造成高延迟。
active-defrag-cycle-max 50
```
