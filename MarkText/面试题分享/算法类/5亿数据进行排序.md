# 超大数据量排序问题

## 参考博文

1. [从一道高大上的面试题来学习位图算法BitMap](https://zhuanlan.zhihu.com/p/379713260)

## 原题

> 华为二面：一个文件里面有5亿个数据，一行一个，没有重复的，进行排序，可用内存只有1G

## 解题

1. 传统排序有：冒泡排序、插入排序、快速排序等。这些排序都是在内存里进行排序，也叫内排序，顾名思义即一次性需全部加载完数据到内存再进行排序。理论上可以解决所有排序问题，只要内存给够，时间给够。但是题干里限制了只有`1G`内存可用，这里我们简单计算了一下5亿数据大致要占用接近`2G`内存，已经超了，这些方案只能弃用。当然这也是这个题故意为之，就是不希望你们使用这些内排序。

2. 既然内排序不行，是否可使用外排序来协助呢。比如多路归并排序，采用分治的思想，把大文件拆分为多个内存能承载的小文件保存在磁盘里，然后在各小文件里使用上面的内排序来完成排序，最后把这些已排序的文件再按序合并进来即可。从理论上这个方案是可行的，只要把大文件拆分，分别排序再合并即可。这里难点在合并结果，可以逐一读取各小文件里当前的最小值，然后对比选出其中的最小值保存到结果文件，被取走的文件继续拿下一个最小值出来等待，直到所有文件都取完，也即完成了排序。

3. 上面的外排序存在一个缺点，就是外存操作，速度慢，步骤多。那么有没有直接内存操作即可完成又非常快的排序方法呢。有一个`bitmap`的东西可以实现。`bitmap`里面每一个数字只占用一个`bit`位，`Int`型大数字一般需要32个`bit`位，上面的5亿数据使用`bitmap`后占用的内存极限情况下只有上面方案的1/32，也即不到`100M`，内存不是问题了。而且`bitmap`天然就是已排好序，无需做排序算法，只需把数据读取进来就已经排好序。然后从头开始读取，遇到`bit`位为1的输出偏移量即可。但是`bitmap`不能处理重复数据排序问题，需要增加额外的操作来协助，比如出现重复数据则记录其重复次数，在读取数据时增加一个判断，把重复数据也读取进来。

## 总结

1. 直接使用传统的内排序不可行，原因是有内存限制，即使无内存限制也会比较慢，数据量太大

2. 既然内排序不行，外排序在理论上就一定可行，但是也存在外排序慢的问题

3. `bitmap`就很好的解决了内存和排序速度的问题，当然也是存在一些缺点的，比如有时太过于稀疏，这个可以使用`Google`的`EWAHCompressedBitmap`解决，还有改进版的`RoaringBitmap`可使用

## 扩展

1. [多路归并算法从理论到应用（易懂）_留恋单行路的博客-CSDN博客](https://blog.csdn.net/a574780196/article/details/122646309)

2. [Bitmap算法简介_kongmin_123的博客-CSDN博客](https://blog.csdn.net/kongmin_123/article/details/82222023)

3. [漫画：Bitmap算法 整合版](https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg)

4. 曾经还有一个类似的题目：[有40亿个QQ号码，需在1G内存的机子里完成去重]([一看就懂 详解redis的bitmap（面试加分项） - 掘金](https://juejin.cn/post/7074747080492711943))

5. [高效压缩位图RoaringBitmap的原理与应用 - 简书](https://www.jianshu.com/p/818ac4e90daf)

6. [EWAHCompressedBitmap数据结构及原理_ewah bitmaps_yizishou的博客-CSDN博客](https://blog.csdn.net/yizishou/article/details/78365791)

7. [RoaringBitmap数据结构及原理_long roaring bitmap_yizishou的博客-CSDN博客](https://blog.csdn.net/yizishou/article/details/78342499)
